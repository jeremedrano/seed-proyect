# Cursor Rules - Proyecto CRUD Usuarios con TDD

## ğŸ§ª FilosofÃ­a de Desarrollo: TDD (Test-Driven Development)

### REGLA PRINCIPAL: Siempre escribir tests ANTES del cÃ³digo

**Orden obligatorio para toda nueva funcionalidad:**

1. ğŸ”´ **RED:** Escribir el test que falla
2. ğŸŸ¢ **GREEN:** Escribir cÃ³digo mÃ­nimo para que pase
3. ğŸ”µ **REFACTOR:** Mejorar el cÃ³digo manteniendo tests verdes

### Workflow TDD por Capas:

#### Para implementar una nueva funcionalidad (ej: CreateUser):

**Paso 1: Test Domain (Entidad)**
```python
# tests/unit/domain/test_user_entity.py
def test_user_creation():
    user = User(id=1, email="test@test.com", name="Test", age=25)
    assert user.email == "test@test.com"
```
â†’ Luego implementar `app/domain/entities/user.py`

**Paso 2: Test Application (Use Case)**
```python
# tests/unit/use_cases/test_create_user.py
def test_create_user_use_case(mock_repository):
    use_case = CreateUserUseCase(mock_repository)
    user = use_case.execute("test@test.com", "Test", 25)
    mock_repository.save.assert_called_once()
```
â†’ Luego implementar `app/application/use_cases/create_user.py`

**Paso 3: Test Infrastructure (Repository)**
```python
# tests/integration/test_user_repository.py
def test_repository_saves_user(db_session):
    repo = UserRepositoryImpl(db_session)
    user = User(None, "test@test.com", "Test", 25)
    saved = repo.save(user)
    assert saved.id is not None
```
â†’ Luego implementar `app/infrastructure/database/repositories/user_repository_impl.py`

**Paso 4: Test Presentation (Endpoint)**
```python
# tests/e2e/test_user_endpoints.py
def test_create_user_endpoint(client):
    response = client.post("/api/v1/users/", json={
        "email": "test@test.com", "name": "Test", "age": 25
    })
    assert response.status_code == 201
```
â†’ Luego implementar `app/presentation/api/v1/endpoints/users.py`

---

## ğŸ—ï¸ Clean Architecture

### Reglas de Dependencia:
- âœ… Presentation â†’ Application â†’ Domain â† Infrastructure
- âŒ Domain NUNCA depende de capas externas
- âŒ Application NUNCA depende de Infrastructure o Presentation

### Estructura de archivos:
```
app/
â”œâ”€â”€ domain/           # Entidades e interfaces (sin dependencias)
â”œâ”€â”€ application/      # Use Cases (casos de uso)
â”œâ”€â”€ infrastructure/   # Adaptadores (DB, servicios externos)
â””â”€â”€ presentation/     # API (FastAPI endpoints)
```

---

## ğŸ“ Convenciones de CÃ³digo

### Naming:
- Entidades: `User`, `Product` (PascalCase)
- Use Cases: `CreateUserUseCase`, `GetUserUseCase`
- Repositorios: `UserRepository` (interfaz), `UserRepositoryImpl` (implementaciÃ³n)
- Tests: `test_<what_it_does>`

### Imports:
- Usar imports absolutos: `from app.domain.entities.user import User`
- No dejar imports sin usar
- Ordenar imports: stdlib â†’ third-party â†’ local

### Logging:
- Usar logging exhaustivo en cada capa
- Formato: `LOG.info("Use case: CreateUser - Starting for email=%s", email)`
- Niveles: DEBUG (desarrollo), INFO (operaciones), WARNING (alertas), ERROR (errores)

### Formato de cÃ³digo:
- No abusar de saltos de lÃ­nea (seguir ejemplo en user rules)
- Mantener anotaciones compactas pero legibles
- MÃ¡ximo 100 caracteres por lÃ­nea

---

## âœ… Tests

### OrganizaciÃ³n de Tests:
```
tests/
â”œâ”€â”€ unit/          # Tests sin dependencias externas (rÃ¡pidos)
â”‚   â”œâ”€â”€ domain/    # Tests de entidades
â”‚   â””â”€â”€ use_cases/ # Tests de use cases (con mocks)
â”œâ”€â”€ integration/   # Tests con DB (en memoria)
â””â”€â”€ e2e/          # Tests de endpoints (servidor completo)
```

### Comandos:
```bash
pytest tests/ -v                    # Todos los tests
pytest tests/unit/ -v               # Solo unitarios (rÃ¡pidos)
pytest tests/e2e/ -v                # Solo e2e
pytest tests/ --cov=app             # Con cobertura
ptw tests/                          # Watch mode (TDD)
```

### Cobertura mÃ­nima:
- **Unit tests:** > 90% de domain y application
- **Integration tests:** Repositorios completos
- **E2E tests:** Happy paths de todos los endpoints

---

## ğŸš« Prohibiciones

### NO hacer:
- âŒ Implementar cÃ³digo sin test previo
- âŒ Commitear cÃ³digo con tests fallando
- âŒ Domain con dependencias a frameworks
- âŒ LÃ³gica de negocio en controllers (presentation)
- âŒ Dejar imports sin usar
- âŒ Usar `print()` (usar logging)
- âŒ Hardcodear valores (usar config o env vars)
- âŒ Hacer queries SQL directos (usar ORM)

### Siempre hacer:
- âœ… Test primero (TDD)
- âœ… Un test, un assert principal
- âœ… Nombres descriptivos
- âœ… CÃ³digo simple y legible
- âœ… Refactorizar con tests verdes
- âœ… Logging en operaciones importantes

---

## ğŸ“‹ Checklist antes de implementar una feature:

- [ ] Â¿EscribÃ­ el test primero? (ğŸ”´ RED)
- [ ] Â¿El test falla por la razÃ³n correcta?
- [ ] Â¿EscribÃ­ el cÃ³digo mÃ­nimo para pasar? (ğŸŸ¢ GREEN)
- [ ] Â¿Todos los tests pasan?
- [ ] Â¿RefactoricÃ© mejorando el diseÃ±o? (ğŸ”µ REFACTOR)
- [ ] Â¿La cobertura se mantiene alta?
- [ ] Â¿El cÃ³digo sigue Clean Architecture?
- [ ] Â¿AgreguÃ© logging apropiado?
- [ ] Â¿DocumentÃ© con docstrings?
- [ ] Â¿No dejÃ© imports sin usar?

---

## ğŸ¯ Objetivo del Proyecto

**PoC:** CRUD de usuarios sin autenticaciÃ³n, con Clean Architecture y TDD.

**Futuro:** Agregar autenticaciÃ³n JWT, compliance, y otras features sin tocar cÃ³digo existente (gracias a Clean Architecture).

---

## ğŸ“š Referencias

- [Clean Architecture (Uncle Bob)](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)
- [TDD by Example (Kent Beck)](https://www.amazon.com/Test-Driven-Development-Kent-Beck/dp/0321146530)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [Pytest Documentation](https://docs.pytest.org/)

